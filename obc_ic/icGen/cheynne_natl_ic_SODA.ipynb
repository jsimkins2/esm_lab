{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray\n",
    "import xesmf\n",
    "\n",
    "# Manually adding this to the path to \n",
    "# avoid problems installing on analysis. \n",
    "# https://github.com/raphaeldussin/HCtFlood\n",
    "# code courtesy of Raphael Dussin - https://github.com/raphaeldussin/HCtFlood/blob/master/HCtFlood/kara.py\n",
    "\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "from dask.base import tokenize\n",
    "import dask.array as dsa\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def flood_kara(data, xdim='lon', ydim='lat', zdim='z', tdim='time',\n",
    "               spval=1e+15):\n",
    "    \"\"\"Apply extrapolation onto land from Kara algo.\n",
    "    Arguments:\n",
    "        data {xarray.DataArray} -- input data\n",
    "    Keyword Arguments:\n",
    "        xdim {str} -- name of x dimension (default: {'lon'})\n",
    "        ydim {str} -- name of y dimension (default: {'lat'})\n",
    "        zdim {str} -- name of z dimension (default: {'z'})\n",
    "        tdim {str} -- name of time dimension (default: {'time'})\n",
    "        spval {float} -- missing value (default: {1e+15})\n",
    "    Returns:\n",
    "        xarray.DataArray -- result of the extrapolation\n",
    "    \"\"\"\n",
    "    # check for input data shape\n",
    "    if tdim not in data.dims:\n",
    "        data = data.expand_dims(dim=tdim)\n",
    "    if zdim not in data.dims:\n",
    "        data = data.expand_dims(dim=zdim)\n",
    "\n",
    "    nrec = len(data[tdim])\n",
    "    nlev = len(data[zdim])\n",
    "    ny = len(data[ydim])\n",
    "    nx = len(data[xdim])\n",
    "    shape = (nrec, nlev, ny, nx)\n",
    "    chunks = (1, 1, ny, nx)\n",
    "\n",
    "    def compute_chunk(zlev, trec):\n",
    "        data_slice = data.isel({tdim: trec, zdim: zlev})\n",
    "        return flood_kara_xr(data_slice, spval=spval)[None, None]\n",
    "\n",
    "    name = str(data.name) + '-' + tokenize(data.name, shape)\n",
    "    dsk = {(name, rec, lev, 0, 0,): (compute_chunk, lev, rec)\n",
    "           for lev in range(nlev)\n",
    "           for rec in range(nrec)}\n",
    "\n",
    "    out = dsa.Array(dsk, name, chunks,\n",
    "                    dtype=data.dtype, shape=shape)\n",
    "\n",
    "    xout = xr.DataArray(data=out, name=str(data.name),\n",
    "                        coords={tdim: data[tdim],\n",
    "                                zdim: data[zdim],\n",
    "                                ydim: data[ydim],\n",
    "                                xdim: data[xdim]},\n",
    "                        dims=(tdim, zdim, ydim, xdim))\n",
    "\n",
    "    # rechunk the result\n",
    "    xout = xout.chunk({tdim: 1, zdim: nlev, ydim: ny, xdim: nx})\n",
    "\n",
    "    return xout\n",
    "\n",
    "def flood_kara_xr(dataarray, spval=1e+15):\n",
    "    \"\"\"Apply flood_kara on a xarray.dataarray\n",
    "    Arguments:\n",
    "        dataarray {xarray.DataArray} -- input 2d data array\n",
    "    Keyword Arguments:\n",
    "        spval {float} -- missing value (default: {1e+15})\n",
    "    Returns:\n",
    "        numpy.ndarray -- field after extrapolation\n",
    "    \"\"\"\n",
    "\n",
    "    masked_array = dataarray.squeeze().to_masked_array()\n",
    "    out = flood_kara_ma(masked_array, spval=spval)\n",
    "    return out\n",
    "\n",
    "def flood_kara_ma(masked_array, spval=1e+15):\n",
    "    \"\"\"Apply flood_kara on a numpy masked array\n",
    "    Arguments:\n",
    "        masked_array {np.ma.masked_array} -- array to extrapolate\n",
    "    Keyword Arguments:\n",
    "        spval {float} -- missing value (default: {1e+15})\n",
    "    Returns:\n",
    "        out -- field after extrapolation\n",
    "    \"\"\"\n",
    "\n",
    "    field = masked_array.data\n",
    "\n",
    "    if np.isnan(field).all():\n",
    "        # all the values are NaN, can't do anything\n",
    "        out = field.copy()\n",
    "    else:\n",
    "        # proceed with extrapolation\n",
    "        field[np.isnan(field)] = spval\n",
    "        mask = np.ones(field.shape)\n",
    "        mask[masked_array.mask] = 0\n",
    "        out = flood_kara_raw(field, mask)\n",
    "    return out\n",
    "\n",
    "\n",
    "def flood_kara_raw(field, mask, nmax=1000):\n",
    "    \"\"\"Extrapolate land values onto land using the kara method\n",
    "    (https://doi.org/10.1175/JPO2984.1)\n",
    "    Arguments:\n",
    "        field {np.ndarray} -- field to extrapolate\n",
    "        mask {np.ndarray} -- land/sea binary mask (0/1)\n",
    "    Keyword Arguments:\n",
    "        nmax {int} -- max number of iteration (default: {1000})\n",
    "    Returns:\n",
    "        drowned -- field after extrapolation\n",
    "    \"\"\"\n",
    "\n",
    "    ny, nx = field.shape\n",
    "    nxy = nx * ny\n",
    "    # create fields with halos\n",
    "    ztmp = np.zeros((ny+2, nx+2))\n",
    "    zmask = np.zeros((ny+2, nx+2))\n",
    "    # init the values\n",
    "    ztmp[1:-1, 1:-1] = field.copy()\n",
    "    zmask[1:-1, 1:-1] = mask.copy()\n",
    "\n",
    "    ztmp_new = ztmp.copy()\n",
    "    zmask_new = zmask.copy()\n",
    "    #\n",
    "    nt = 0\n",
    "    while (zmask[1:-1, 1:-1].sum() < nxy) and (nt < nmax):\n",
    "        for jj in np.arange(1, ny+1):\n",
    "            for ji in np.arange(1, nx+1):\n",
    "\n",
    "                # compute once those indexes\n",
    "                jjm1 = jj-1\n",
    "                jjp1 = jj+1\n",
    "                jim1 = ji-1\n",
    "                jip1 = ji+1\n",
    "\n",
    "                if (zmask[jj, ji] == 0):\n",
    "                    c6 = 1 * zmask[jjm1, jim1]\n",
    "                    c7 = 2 * zmask[jjm1, ji]\n",
    "                    c8 = 1 * zmask[jjm1, jip1]\n",
    "\n",
    "                    c4 = 2 * zmask[jj, jim1]\n",
    "                    c5 = 2 * zmask[jj, jip1]\n",
    "\n",
    "                    c1 = 1 * zmask[jjp1, jim1]\n",
    "                    c2 = 2 * zmask[jjp1, ji]\n",
    "                    c3 = 1 * zmask[jjp1, jip1]\n",
    "\n",
    "                    ctot = c1 + c2 + c3 + c4 + c5 + c6 + c7 + c8\n",
    "\n",
    "                    if (ctot >= 3):\n",
    "                        # compute the new value for this point\n",
    "                        zval = (c6 * ztmp[jjm1, jim1] +\n",
    "                                c7 * ztmp[jjm1, ji] +\n",
    "                                c8 * ztmp[jjm1, jip1] +\n",
    "                                c4 * ztmp[jj, jim1] +\n",
    "                                c5 * ztmp[jj, jip1] +\n",
    "                                c1 * ztmp[jjp1, jim1] +\n",
    "                                c2 * ztmp[jjp1, ji] +\n",
    "                                c3 * ztmp[jjp1, jip1]) / ctot\n",
    "\n",
    "                        # update value in field array\n",
    "                        ztmp_new[jj, ji] = zval\n",
    "                        # set the mask to sea\n",
    "                        zmask_new[jj, ji] = 1\n",
    "        nt += 1\n",
    "        ztmp = ztmp_new.copy()\n",
    "        zmask = zmask_new.copy()\n",
    "\n",
    "        if nt == nmax:\n",
    "            raise ValueError('number of iterations exceeded maximum, '\n",
    "                             'try increasing nmax')\n",
    "\n",
    "    drowned = ztmp[1:-1, 1:-1]\n",
    "\n",
    "    return drowned\n",
    "\n",
    "def vgrid_to_interfaces(vgrid, max_depth=6500.0):\n",
    "    \"\"\"Convert layer thicknesses to interface depths.\n",
    "    Args:\n",
    "        vgrid: array of layer thicknesses.\n",
    "        max_depth: maximum depth of the model. The lowest interface depth will be set to this.\n",
    "    Returns:\n",
    "        Array of interface depths.     \n",
    "    \"\"\"\n",
    "    if isinstance(vgrid, xarray.DataArray):\n",
    "        vgrid = vgrid.data\n",
    "    zi = np.concatenate([[0], np.cumsum(vgrid)])\n",
    "    zi[-1] = max_depth\n",
    "    return zi\n",
    "\n",
    "\n",
    "def vgrid_to_layers(vgrid, max_depth=6500.0):\n",
    "    \"\"\"Convert layer thicknesses to depths of layer midpoints.\n",
    "    Args:\n",
    "        vgrid: array of layer thicknesses.\n",
    "        max_depth: maximum depth of the model. The lowest interface depth will be set to this.\n",
    "    Returns:\n",
    "        Array of layer depths.     \n",
    "    \"\"\"\n",
    "    if isinstance(vgrid, xarray.DataArray):\n",
    "        vgrid = vgrid.data\n",
    "    ints = vgrid_to_interfaces(vgrid, max_depth=max_depth)\n",
    "    z = (ints + np.roll(ints, shift=1)) / 2\n",
    "    layers = z[1:]\n",
    "    return layers\n",
    "\n",
    "\n",
    "def rotate_uv(u, v, angle, in_degrees=False):\n",
    "    \"\"\"Rotate velocities from earth-relative to model-relative.\n",
    "    Args:\n",
    "        u: west-east component of velocity.\n",
    "        v: south-north component of velocity.\n",
    "        angle: angle of rotation from true north to model north.\n",
    "        in_degrees (bool): typically angle is in radians, but set this to True if it is in degrees.\n",
    "    Returns:\n",
    "        Model-relative west-east and south-north components of velocity.\n",
    "    \"\"\"\n",
    "    if in_degrees:\n",
    "        angle = np.radians(angle)\n",
    "    urot = np.cos(angle) * u + np.sin(angle) * v\n",
    "    vrot = -np.sin(angle) * u + np.cos(angle) * v\n",
    "    return urot, vrot\n",
    "\n",
    "\n",
    "def interpolate_flood_tracers(ds, target_grid):\n",
    "    \"\"\"Interpolate and flood data at tracer points (temperature, salinity, free surface).\n",
    "    Args:\n",
    "        ds (xarray.Dataset): Dataset with variables temp, salt, and ssh.\n",
    "        target_grid (xarray.Dataset): Model supergrid with variables x, y and coords nxp, nyp.\n",
    "    Returns:\n",
    "        xarray.Dataset: Dataset flooded and interpolated to MOM tracer grid. \n",
    "    \"\"\"\n",
    "    # Flood temperature and salinity over land.\n",
    "    flooded = xarray.merge((\n",
    "        flood_kara(ds[v], zdim='zl') for v in ['temp', 'salt']\n",
    "    ))\n",
    "    \n",
    "    # Flood ssh separately to avoid extra z=0\n",
    "    flooded['ssh'] = flood_kara(ds['ssh']).isel(z=0).drop('z')\n",
    "    \n",
    "    # Interpolate\n",
    "    target_points = (\n",
    "        target_grid\n",
    "        [['x', 'y']]\n",
    "        .isel(nxp=slice(1, None, 2), nyp=slice(1, None, 2))\n",
    "        .rename({'y': 'lat', 'x': 'lon', 'nxp': 'xh', 'nyp': 'yh'})\n",
    "    )\n",
    "    soda_to_mom = xesmf.Regridder(\n",
    "        flooded, \n",
    "        target_points, \n",
    "        method='bilinear', \n",
    "        filename='regrid_soda_tracers.nc',\n",
    "        reuse_weights=False,\n",
    "        periodic=True\n",
    "    )\n",
    "    interped = soda_to_mom(flooded).drop(['lon', 'lat'])\n",
    "    return interped\n",
    "\n",
    "\n",
    "def interpolate_flood_velocity(ds, target_grid):\n",
    "    \"\"\"Interpolate and flood velocity data.\n",
    "    Args:\n",
    "        ds (xarray.Dataset): Dataset with variables u and v.\n",
    "        target_grid (xarray.Dataset): Model supergrid with variables x, y and coords nxp, nyp.\n",
    "    Returns:\n",
    "        xarray.Dataset: Dataset flooded and interpolated to MOM velocity grid. \n",
    "    \"\"\"\n",
    "    # Flood over land.\n",
    "    flooded = xarray.merge((\n",
    "        flood_kara(ds[v], zdim='zl') for v in ['u', 'v']\n",
    "    ))\n",
    "\n",
    "    # Interpolate u and v onto supergrid to make rotation possible\n",
    "    target_uv = (\n",
    "        target_grid\n",
    "        [['x', 'y']]\n",
    "        .rename({'y': 'lat', 'x': 'lon'})\n",
    "    )\n",
    "    soda_to_uv = xesmf.Regridder(\n",
    "        ds, target_uv, \n",
    "        filename='regrid_soda_uv.nc',\n",
    "        method='nearest_s2d',\n",
    "        reuse_weights=False,\n",
    "        periodic=True\n",
    "    )\n",
    "    interped_uv = soda_to_uv(flooded[['u', 'v']]).drop(['lon', 'lat'])\n",
    "    urot, vrot = rotate_uv(interped_uv['u'], interped_uv['v'], target_grid['angle_dx'])\n",
    "    # Subset onto u and v points.\n",
    "    uo = urot.isel(nxp=slice(0, None, 2), nyp=slice(1, None, 2)).rename({'nxp': 'xq', 'nyp': 'yh'})\n",
    "    uo.name = 'u'\n",
    "    vo = vrot.isel(nxp=slice(1, None, 2), nyp=slice(0, None, 2)).rename({'nxp': 'xh', 'nyp': 'yq'})\n",
    "    vo.name = 'v'\n",
    "    \n",
    "    interped = (\n",
    "        xarray.merge((uo, vo))\n",
    "        .transpose('time', 'zl', 'yh', 'yq', 'xh', 'xq')\n",
    "    )\n",
    "\n",
    "    return interped\n",
    "\n",
    "\n",
    "def write_initial(soda_file, vgrid_file, grid_file, start_date, output_file):\n",
    "    \"\"\"Interpolate initial conditions for MOM from a SODA file and write to a new file.\n",
    "    Args:\n",
    "        soda_file (str): Path to SODA file to use for initial conditions.\n",
    "        vgrid_file (str): Path to vertical grid to interpolate data to.\n",
    "        grid_file (str): Path to horizontal grid file (ocean_hgrid.nc) to interpolate data to.\n",
    "        start_date (np.datetime64): Overwrite the SODA datetime with this datetime. Useful if model start date and SODA 5-day dates do not match.\n",
    "        output_file (str): Write resulting initial conditions to this file.\n",
    "    \"\"\"\n",
    "    vgrid = xarray.open_dataarray(vgrid_file)\n",
    "    z = vgrid_to_layers(vgrid)\n",
    "    ztarget = xarray.DataArray(\n",
    "        z,\n",
    "        name='zl',\n",
    "        dims=['zl'], \n",
    "        coords={'zl': z}\n",
    "    )\n",
    "\n",
    "    soda = (\n",
    "        xarray.open_dataset(soda_file)\n",
    "        .rename({'st_ocean': 'z'})\n",
    "        [['temp', 'salt', 'ssh', 'u', 'v']]\n",
    "    )\n",
    "\n",
    "    # Interpolate SODA vertically onto target grid.\n",
    "    # Depths below bottom of SODA are filled by extrapolating the deepest available value.\n",
    "    revert = soda.interp(z=ztarget, kwargs={'fill_value': 'extrapolate'}).ffill('zl', limit=None)\n",
    "\n",
    "    # Split SODA into data on tracer and velocity points\n",
    "    tracers = revert[['temp', 'salt', 'ssh']].rename({'xt_ocean': 'lon', 'yt_ocean': 'lat'})\n",
    "    velocity = revert[['u', 'v']].rename({'xu_ocean': 'lon', 'yu_ocean': 'lat'})\n",
    "\n",
    "    # Horizontally interpolated the vertically interpolated\n",
    "    # and flooded data onto the MOM grid.\n",
    "    grid = xarray.open_dataset(grid_file)\n",
    "\n",
    "    interped = xarray.merge((\n",
    "        interpolate_flood_tracers(tracers, grid),\n",
    "        interpolate_flood_velocity(velocity, grid)\n",
    "    ))\n",
    "\n",
    "    # Overwrite the SODA file time with the intended model start date.\n",
    "    interped['time'] = (('time', ), [start_date])\n",
    "\n",
    "    # Fix output metadata, including removing all _FillValues.\n",
    "    all_vars = list(interped.data_vars.keys()) + list(interped.coords.keys())\n",
    "    encodings = {v: {'_FillValue': None} for v in all_vars}\n",
    "    encodings['time'].update({'dtype':'float64', 'calendar': 'gregorian'})\n",
    "    interped['zl'].attrs = {\n",
    "        'units': 'meter',\n",
    "        'cartesian_axis': 'Z',\n",
    "        'positive': 'down'\n",
    "    }\n",
    "\n",
    "    interped.to_netcdf(\n",
    "        output_file,\n",
    "        format='NETCDF3_64BIT',\n",
    "        engine='netcdf4',\n",
    "        encoding=encodings,\n",
    "        unlimited_dims='time'\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    # Use SODA data centered on 1992-12-30.\n",
    "    # Model start date is 1993-01-01.\n",
    "    # https://dsrs.atmos.umd.edu/DATA/soda3.12.2/REGRIDED/ocean/soda3.12.2_5dy_ocean_reg_1993_01_04.nc\n",
    "    soda_file = '/glade/scratch/jsimkins/SODA3.12.2/soda3.12.2_5dy_ocean_reg_1993_01_04.nc'\n",
    "    start_date = np.datetime64('1993-01-02T00:00:00')\n",
    "    # Used in filename below, don't change\n",
    "    start_str = np.datetime_as_string(start_date, unit='D')\n",
    "    \n",
    "    # Save the ICs here:\n",
    "    output_file = f'/glade/u/home/jsimkins/obc_ic/natlGrid/soda_ic_75z_{start_str}.nc'\n",
    "\n",
    "    # Model vertical grid:\n",
    "    vgrid_file = '/glade/u/home/jsimkins/obc_ic/natlGrid/vgrid_dz.nc'\n",
    "\n",
    "    # Model horizontal grid:\n",
    "    grid_file = '/glade/u/home/jsimkins/obc_ic/natlGrid/natl_ocean_hgrid.nc'\n",
    "\n",
    "    write_initial(soda_file, vgrid_file, grid_file, start_date, output_file)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (Layer: 41, interfaces: 42)\n",
       "Coordinates:\n",
       "  * Layer    (Layer) float64 1.001e+03 1.001e+03 ... 1.037e+03 1.037e+03\n",
       "Dimensions without coordinates: interfaces\n",
       "Data variables:\n",
       "    dz       (Layer) float64 1.0 1.8 3.24 4.68 4.93 ... 261.8 400.0 600.0 600.0\n",
       "    sigma2   (interfaces) float64 1.001e+03 1.001e+03 ... 1.037e+03 1.038e+03\n",
       "Attributes:\n",
       "    history:  hycom2vgrid</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-a5a0fac3-cd88-40b0-91fc-931606edd80c' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-a5a0fac3-cd88-40b0-91fc-931606edd80c' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>Layer</span>: 41</li><li><span>interfaces</span>: 42</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-beabce8d-ba77-41c5-bd8d-7b277404df8e' class='xr-section-summary-in' type='checkbox'  checked><label for='section-beabce8d-ba77-41c5-bd8d-7b277404df8e' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>Layer</span></div><div class='xr-var-dims'>(Layer)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.001e+03 1.001e+03 ... 1.037e+03</div><input id='attrs-c2b55ab1-329e-4175-b59d-f70226be926f' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c2b55ab1-329e-4175-b59d-f70226be926f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ff03c7c4-6891-49e6-bfa7-c035665ce2ab' class='xr-var-data-in' type='checkbox'><label for='data-ff03c7c4-6891-49e6-bfa7-c035665ce2ab' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>kg/m3</dd><dt><span>long_name :</span></dt><dd>Layer target potential density referenced to 2000 dbars</dd></dl></div><div class='xr-var-data'><pre>array([1001.    , 1001.1   , 1001.2   , 1001.3   , 1001.4   , 1001.5   ,\n",
       "       1001.6   , 1001.7   , 1001.8   , 1001.9   , 1002.    , 1002.1   ,\n",
       "       1002.2   , 1009.3625, 1023.7375, 1031.325 , 1031.95  , 1032.55  ,\n",
       "       1033.15  , 1033.7375, 1034.2875, 1034.775 , 1035.175 , 1035.5   ,\n",
       "       1035.785 , 1036.02  , 1036.205 , 1036.37  , 1036.51  , 1036.615 ,\n",
       "       1036.6975, 1036.7675, 1036.83  , 1036.895 , 1036.9625, 1037.0175,\n",
       "       1037.06  , 1037.1075, 1037.185 , 1037.2975, 1037.42  ])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-fde459bf-0681-44f4-a3c8-05bf0c51bb9f' class='xr-section-summary-in' type='checkbox'  checked><label for='section-fde459bf-0681-44f4-a3c8-05bf0c51bb9f' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>dz</span></div><div class='xr-var-dims'>(Layer)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-144132c3-6735-474f-9c80-1257042d4e65' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-144132c3-6735-474f-9c80-1257042d4e65' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-314a93dc-1210-44ee-acd0-b3cf8c4d68fb' class='xr-var-data-in' type='checkbox'><label for='data-314a93dc-1210-44ee-acd0-b3cf8c4d68fb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>m</dd><dt><span>long_name :</span></dt><dd>z* coordinate level thickness</dd></dl></div><div class='xr-var-data'><pre>array([  1.  ,   1.8 ,   3.24,   4.68,   4.93,   5.81,   6.87,   8.  ,   8.  ,\n",
       "         8.  ,   8.  ,   8.  ,   8.  ,   8.  ,   8.  ,   8.  ,   8.  ,   8.  ,\n",
       "         8.  ,   8.  ,   8.  ,   8.  ,   8.  ,  10.  ,  16.4 ,  35.92,  42.38,\n",
       "        50.02,  59.02,  69.64,  82.18,  96.97, 114.43, 135.02, 159.33, 188.01,\n",
       "       221.84, 261.78, 400.  , 600.  , 600.  ])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sigma2</span></div><div class='xr-var-dims'>(interfaces)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-b0cfabda-6a2a-4c21-b63d-fcb139955060' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b0cfabda-6a2a-4c21-b63d-fcb139955060' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8f589e9c-72dc-4776-b616-031d260e09ac' class='xr-var-data-in' type='checkbox'><label for='data-8f589e9c-72dc-4776-b616-031d260e09ac' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>kg/m3</dd><dt><span>long_name :</span></dt><dd>Interface target potential density referenced to 2000 dbars with   1.000% compressibility</dd></dl></div><div class='xr-var-data'><pre>array([1000.825377, 1000.975398, 1001.075454, 1001.175564, 1001.275728,\n",
       "       1001.375901, 1001.476107, 1001.576353, 1001.676642, 1001.77693 ,\n",
       "       1001.877218, 1001.977507, 1002.077796, 1002.178084, 1016.401806,\n",
       "       1030.922895, 1031.573104, 1032.173073, 1032.773138, 1033.373406,\n",
       "       1033.94899 , 1034.474656, 1034.925638, 1035.278063, 1035.581766,\n",
       "       1035.856888, 1036.06256 , 1036.238282, 1036.40524 , 1036.531892,\n",
       "       1036.628285, 1036.709872, 1036.781804, 1036.850551, 1036.935804,\n",
       "       1037.027284, 1037.100532, 1037.163777, 1037.232911, 1037.346655,\n",
       "       1037.498821, 1037.681203])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-1a7467e1-39b5-428b-ae63-636c95c17002' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1a7467e1-39b5-428b-ae63-636c95c17002' class='xr-section-summary' >Attributes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>history :</span></dt><dd>hycom2vgrid</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (Layer: 41, interfaces: 42)\n",
       "Coordinates:\n",
       "  * Layer    (Layer) float64 1.001e+03 1.001e+03 ... 1.037e+03 1.037e+03\n",
       "Dimensions without coordinates: interfaces\n",
       "Data variables:\n",
       "    dz       (Layer) float64 ...\n",
       "    sigma2   (interfaces) float64 ...\n",
       "Attributes:\n",
       "    history:  hycom2vgrid"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "a = xr.open_dataset('/Users/james/Documents/Github/esm_lab/obc_ic/natlGrid/mom6_vgrid.nc')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1001.    , 1001.1   , 1001.2   , 1001.3   , 1001.4   , 1001.5   ,\n",
       "       1001.6   , 1001.7   , 1001.8   , 1001.9   , 1002.    , 1002.1   ,\n",
       "       1002.2   , 1009.3625, 1023.7375, 1031.325 , 1031.95  , 1032.55  ,\n",
       "       1033.15  , 1033.7375, 1034.2875, 1034.775 , 1035.175 , 1035.5   ,\n",
       "       1035.785 , 1036.02  , 1036.205 , 1036.37  , 1036.51  , 1036.615 ,\n",
       "       1036.6975, 1036.7675, 1036.83  , 1036.895 , 1036.9625, 1037.0175,\n",
       "       1037.06  , 1037.1075, 1037.185 , 1037.2975, 1037.42  ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.Layer.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray\n",
    "import xesmf\n",
    "\n",
    "# Manually adding this to the path to \n",
    "# avoid problems installing on analysis. \n",
    "# https://github.com/raphaeldussin/HCtFlood\n",
    "# code courtesy of Raphael Dussin - https://github.com/raphaeldussin/HCtFlood/blob/master/HCtFlood/kara.py\n",
    "\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "from dask.base import tokenize\n",
    "import dask.array as dsa\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def flood_kara(data, xdim='lon', ydim='lat', zdim='z', tdim='time',\n",
    "               spval=1e+15):\n",
    "    \"\"\"Apply extrapolation onto land from Kara algo.\n",
    "    Arguments:\n",
    "        data {xarray.DataArray} -- input data\n",
    "    Keyword Arguments:\n",
    "        xdim {str} -- name of x dimension (default: {'lon'})\n",
    "        ydim {str} -- name of y dimension (default: {'lat'})\n",
    "        zdim {str} -- name of z dimension (default: {'z'})\n",
    "        tdim {str} -- name of time dimension (default: {'time'})\n",
    "        spval {float} -- missing value (default: {1e+15})\n",
    "    Returns:\n",
    "        xarray.DataArray -- result of the extrapolation\n",
    "    \"\"\"\n",
    "    # check for input data shape\n",
    "    if tdim not in data.dims:\n",
    "        data = data.expand_dims(dim=tdim)\n",
    "    if zdim not in data.dims:\n",
    "        data = data.expand_dims(dim=zdim)\n",
    "\n",
    "    nrec = len(data[tdim])\n",
    "    nlev = len(data[zdim])\n",
    "    ny = len(data[ydim])\n",
    "    nx = len(data[xdim])\n",
    "    shape = (nrec, nlev, ny, nx)\n",
    "    chunks = (1, 1, ny, nx)\n",
    "\n",
    "    def compute_chunk(zlev, trec):\n",
    "        data_slice = data.isel({tdim: trec, zdim: zlev})\n",
    "        return flood_kara_xr(data_slice, spval=spval)[None, None]\n",
    "\n",
    "    name = str(data.name) + '-' + tokenize(data.name, shape)\n",
    "    dsk = {(name, rec, lev, 0, 0,): (compute_chunk, lev, rec)\n",
    "           for lev in range(nlev)\n",
    "           for rec in range(nrec)}\n",
    "\n",
    "    out = dsa.Array(dsk, name, chunks,\n",
    "                    dtype=data.dtype, shape=shape)\n",
    "\n",
    "    xout = xr.DataArray(data=out, name=str(data.name),\n",
    "                        coords={tdim: data[tdim],\n",
    "                                zdim: data[zdim],\n",
    "                                ydim: data[ydim],\n",
    "                                xdim: data[xdim]},\n",
    "                        dims=(tdim, zdim, ydim, xdim))\n",
    "\n",
    "    # rechunk the result\n",
    "    xout = xout.chunk({tdim: 1, zdim: nlev, ydim: ny, xdim: nx})\n",
    "\n",
    "    return xout\n",
    "\n",
    "def flood_kara_xr(dataarray, spval=1e+15):\n",
    "    \"\"\"Apply flood_kara on a xarray.dataarray\n",
    "    Arguments:\n",
    "        dataarray {xarray.DataArray} -- input 2d data array\n",
    "    Keyword Arguments:\n",
    "        spval {float} -- missing value (default: {1e+15})\n",
    "    Returns:\n",
    "        numpy.ndarray -- field after extrapolation\n",
    "    \"\"\"\n",
    "\n",
    "    masked_array = dataarray.squeeze().to_masked_array()\n",
    "    out = flood_kara_ma(masked_array, spval=spval)\n",
    "    return out\n",
    "\n",
    "def flood_kara_ma(masked_array, spval=1e+15):\n",
    "    \"\"\"Apply flood_kara on a numpy masked array\n",
    "    Arguments:\n",
    "        masked_array {np.ma.masked_array} -- array to extrapolate\n",
    "    Keyword Arguments:\n",
    "        spval {float} -- missing value (default: {1e+15})\n",
    "    Returns:\n",
    "        out -- field after extrapolation\n",
    "    \"\"\"\n",
    "\n",
    "    field = masked_array.data\n",
    "\n",
    "    if np.isnan(field).all():\n",
    "        # all the values are NaN, can't do anything\n",
    "        out = field.copy()\n",
    "    else:\n",
    "        # proceed with extrapolation\n",
    "        field[np.isnan(field)] = spval\n",
    "        mask = np.ones(field.shape)\n",
    "        mask[masked_array.mask] = 0\n",
    "        out = flood_kara_raw(field, mask)\n",
    "    return out\n",
    "\n",
    "\n",
    "def flood_kara_raw(field, mask, nmax=1000):\n",
    "    \"\"\"Extrapolate land values onto land using the kara method\n",
    "    (https://doi.org/10.1175/JPO2984.1)\n",
    "    Arguments:\n",
    "        field {np.ndarray} -- field to extrapolate\n",
    "        mask {np.ndarray} -- land/sea binary mask (0/1)\n",
    "    Keyword Arguments:\n",
    "        nmax {int} -- max number of iteration (default: {1000})\n",
    "    Returns:\n",
    "        drowned -- field after extrapolation\n",
    "    \"\"\"\n",
    "\n",
    "    ny, nx = field.shape\n",
    "    nxy = nx * ny\n",
    "    # create fields with halos\n",
    "    ztmp = np.zeros((ny+2, nx+2))\n",
    "    zmask = np.zeros((ny+2, nx+2))\n",
    "    # init the values\n",
    "    ztmp[1:-1, 1:-1] = field.copy()\n",
    "    zmask[1:-1, 1:-1] = mask.copy()\n",
    "\n",
    "    ztmp_new = ztmp.copy()\n",
    "    zmask_new = zmask.copy()\n",
    "    #\n",
    "    nt = 0\n",
    "    while (zmask[1:-1, 1:-1].sum() < nxy) and (nt < nmax):\n",
    "        for jj in np.arange(1, ny+1):\n",
    "            for ji in np.arange(1, nx+1):\n",
    "\n",
    "                # compute once those indexes\n",
    "                jjm1 = jj-1\n",
    "                jjp1 = jj+1\n",
    "                jim1 = ji-1\n",
    "                jip1 = ji+1\n",
    "\n",
    "                if (zmask[jj, ji] == 0):\n",
    "                    c6 = 1 * zmask[jjm1, jim1]\n",
    "                    c7 = 2 * zmask[jjm1, ji]\n",
    "                    c8 = 1 * zmask[jjm1, jip1]\n",
    "\n",
    "                    c4 = 2 * zmask[jj, jim1]\n",
    "                    c5 = 2 * zmask[jj, jip1]\n",
    "\n",
    "                    c1 = 1 * zmask[jjp1, jim1]\n",
    "                    c2 = 2 * zmask[jjp1, ji]\n",
    "                    c3 = 1 * zmask[jjp1, jip1]\n",
    "\n",
    "                    ctot = c1 + c2 + c3 + c4 + c5 + c6 + c7 + c8\n",
    "\n",
    "                    if (ctot >= 3):\n",
    "                        # compute the new value for this point\n",
    "                        zval = (c6 * ztmp[jjm1, jim1] +\n",
    "                                c7 * ztmp[jjm1, ji] +\n",
    "                                c8 * ztmp[jjm1, jip1] +\n",
    "                                c4 * ztmp[jj, jim1] +\n",
    "                                c5 * ztmp[jj, jip1] +\n",
    "                                c1 * ztmp[jjp1, jim1] +\n",
    "                                c2 * ztmp[jjp1, ji] +\n",
    "                                c3 * ztmp[jjp1, jip1]) / ctot\n",
    "\n",
    "                        # update value in field array\n",
    "                        ztmp_new[jj, ji] = zval\n",
    "                        # set the mask to sea\n",
    "                        zmask_new[jj, ji] = 1\n",
    "        nt += 1\n",
    "        ztmp = ztmp_new.copy()\n",
    "        zmask = zmask_new.copy()\n",
    "\n",
    "        if nt == nmax:\n",
    "            raise ValueError('number of iterations exceeded maximum, '\n",
    "                             'try increasing nmax')\n",
    "\n",
    "    drowned = ztmp[1:-1, 1:-1]\n",
    "\n",
    "    return drowned\n",
    "\n",
    "def vgrid_to_interfaces(vgrid, max_depth=6500.0):\n",
    "    \"\"\"Convert layer thicknesses to interface depths.\n",
    "    Args:\n",
    "        vgrid: array of layer thicknesses.\n",
    "        max_depth: maximum depth of the model. The lowest interface depth will be set to this.\n",
    "    Returns:\n",
    "        Array of interface depths.     \n",
    "    \"\"\"\n",
    "    if isinstance(vgrid, xarray.DataArray):\n",
    "        vgrid = vgrid.data\n",
    "    zi = np.concatenate([[0], np.cumsum(vgrid)])\n",
    "    zi[-1] = max_depth\n",
    "    return zi\n",
    "\n",
    "\n",
    "def vgrid_to_layers(vgrid, max_depth=6500.0):\n",
    "    \"\"\"Convert layer thicknesses to depths of layer midpoints.\n",
    "    Args:\n",
    "        vgrid: array of layer thicknesses.\n",
    "        max_depth: maximum depth of the model. The lowest interface depth will be set to this.\n",
    "    Returns:\n",
    "        Array of layer depths.     \n",
    "    \"\"\"\n",
    "    if isinstance(vgrid, xarray.DataArray):\n",
    "        vgrid = vgrid.data\n",
    "    ints = vgrid_to_interfaces(vgrid, max_depth=max_depth)\n",
    "    z = (ints + np.roll(ints, shift=1)) / 2\n",
    "    layers = z[1:]\n",
    "    return layers\n",
    "\n",
    "\n",
    "def rotate_uv(u, v, angle, in_degrees=False):\n",
    "    \"\"\"Rotate velocities from earth-relative to model-relative.\n",
    "    Args:\n",
    "        u: west-east component of velocity.\n",
    "        v: south-north component of velocity.\n",
    "        angle: angle of rotation from true north to model north.\n",
    "        in_degrees (bool): typically angle is in radians, but set this to True if it is in degrees.\n",
    "    Returns:\n",
    "        Model-relative west-east and south-north components of velocity.\n",
    "    \"\"\"\n",
    "    if in_degrees:\n",
    "        angle = np.radians(angle)\n",
    "    urot = np.cos(angle) * u + np.sin(angle) * v\n",
    "    vrot = -np.sin(angle) * u + np.cos(angle) * v\n",
    "    return urot, vrot\n",
    "\n",
    "\n",
    "def interpolate_flood_tracers(ds, target_grid):\n",
    "    \"\"\"Interpolate and flood data at tracer points (temperature, salinity, free surface).\n",
    "    Args:\n",
    "        ds (xarray.Dataset): Dataset with variables temp, salt, and ssh.\n",
    "        target_grid (xarray.Dataset): Model supergrid with variables x, y and coords nxp, nyp.\n",
    "    Returns:\n",
    "        xarray.Dataset: Dataset flooded and interpolated to MOM tracer grid. \n",
    "    \"\"\"\n",
    "    # Flood temperature and salinity over land.\n",
    "    flooded = xarray.merge((\n",
    "        flood_kara(ds[v], zdim='zl') for v in ['temp', 'salt']\n",
    "    ))\n",
    "    \n",
    "    # Flood ssh separately to avoid extra z=0\n",
    "    flooded['ssh'] = flood_kara(ds['ssh']).isel(z=0).drop('z')\n",
    "    \n",
    "    # Interpolate\n",
    "    target_points = (\n",
    "        target_grid\n",
    "        [['x', 'y']]\n",
    "        .isel(nxp=slice(1, None, 2), nyp=slice(1, None, 2))\n",
    "        .rename({'y': 'lat', 'x': 'lon', 'nxp': 'xh', 'nyp': 'yh'})\n",
    "    )\n",
    "    soda_to_mom = xesmf.Regridder(\n",
    "        flooded, \n",
    "        target_points, \n",
    "        method='bilinear', \n",
    "        filename='regrid_soda_tracers.nc',\n",
    "        reuse_weights=False,\n",
    "        periodic=True\n",
    "    )\n",
    "    interped = soda_to_mom(flooded).drop(['lon', 'lat'])\n",
    "    return interped\n",
    "\n",
    "\n",
    "def interpolate_flood_velocity(ds, target_grid):\n",
    "    \"\"\"Interpolate and flood velocity data.\n",
    "    Args:\n",
    "        ds (xarray.Dataset): Dataset with variables u and v.\n",
    "        target_grid (xarray.Dataset): Model supergrid with variables x, y and coords nxp, nyp.\n",
    "    Returns:\n",
    "        xarray.Dataset: Dataset flooded and interpolated to MOM velocity grid. \n",
    "    \"\"\"\n",
    "    # Flood over land.\n",
    "    flooded = xarray.merge((\n",
    "        flood_kara(ds[v], zdim='zl') for v in ['u', 'v']\n",
    "    ))\n",
    "\n",
    "    # Interpolate u and v onto supergrid to make rotation possible\n",
    "    target_uv = (\n",
    "        target_grid\n",
    "        [['x', 'y']]\n",
    "        .rename({'y': 'lat', 'x': 'lon'})\n",
    "    )\n",
    "    soda_to_uv = xesmf.Regridder(\n",
    "        ds, target_uv, \n",
    "        filename='regrid_soda_uv.nc',\n",
    "        method='nearest_s2d',\n",
    "        reuse_weights=False,\n",
    "        periodic=True\n",
    "    )\n",
    "    interped_uv = soda_to_uv(flooded[['u', 'v']]).drop(['lon', 'lat'])\n",
    "    urot, vrot = rotate_uv(interped_uv['u'], interped_uv['v'], target_grid['angle_dx'])\n",
    "    # Subset onto u and v points.\n",
    "    uo = urot.isel(nxp=slice(0, None, 2), nyp=slice(1, None, 2)).rename({'nxp': 'xq', 'nyp': 'yh'})\n",
    "    uo.name = 'u'\n",
    "    vo = vrot.isel(nxp=slice(1, None, 2), nyp=slice(0, None, 2)).rename({'nxp': 'xh', 'nyp': 'yq'})\n",
    "    vo.name = 'v'\n",
    "    \n",
    "    interped = (\n",
    "        xarray.merge((uo, vo))\n",
    "        .transpose('time', 'zl', 'yh', 'yq', 'xh', 'xq')\n",
    "    )\n",
    "\n",
    "    return interped\n",
    "\n",
    "\n",
    "def write_initial(soda_file, vgrid_file, grid_file, start_date, output_file):\n",
    "    \"\"\"Interpolate initial conditions for MOM from a SODA file and write to a new file.\n",
    "    Args:\n",
    "        soda_file (str): Path to SODA file to use for initial conditions.\n",
    "        vgrid_file (str): Path to vertical grid to interpolate data to.\n",
    "        grid_file (str): Path to horizontal grid file (ocean_hgrid.nc) to interpolate data to.\n",
    "        start_date (np.datetime64): Overwrite the SODA datetime with this datetime. Useful if model start date and SODA 5-day dates do not match.\n",
    "        output_file (str): Write resulting initial conditions to this file.\n",
    "    \"\"\"\n",
    "    vgrid = xarray.open_dataarray(vgrid_file)\n",
    "    z = vgrid_to_layers(vgrid)\n",
    "    ztarget = xarray.DataArray(\n",
    "        z,\n",
    "        name='zl',\n",
    "        dims=['zl'], \n",
    "        coords={'zl': z}\n",
    "    )\n",
    "\n",
    "    soda = (\n",
    "        xarray.open_dataset(soda_file)\n",
    "        .rename({'st_ocean': 'z'})\n",
    "        [['temp', 'salt', 'ssh', 'u', 'v']]\n",
    "    )\n",
    "\n",
    "    # Interpolate SODA vertically onto target grid.\n",
    "    # Depths below bottom of SODA are filled by extrapolating the deepest available value.\n",
    "    revert = soda.interp(z=ztarget, kwargs={'fill_value': 'extrapolate'}).ffill('zl', limit=None)\n",
    "\n",
    "    # Split SODA into data on tracer and velocity points\n",
    "    tracers = revert[['temp', 'salt', 'ssh']].rename({'xt_ocean': 'lon', 'yt_ocean': 'lat'})\n",
    "    velocity = revert[['u', 'v']].rename({'xu_ocean': 'lon', 'yu_ocean': 'lat'})\n",
    "\n",
    "    # Horizontally interpolated the vertically interpolated\n",
    "    # and flooded data onto the MOM grid.\n",
    "    grid = xarray.open_dataset(grid_file)\n",
    "\n",
    "    interped = xarray.merge((\n",
    "        interpolate_flood_tracers(tracers, grid),\n",
    "        interpolate_flood_velocity(velocity, grid)\n",
    "    ))\n",
    "\n",
    "    # Overwrite the SODA file time with the intended model start date.\n",
    "    interped['time'] = (('time', ), [start_date])\n",
    "\n",
    "    # Fix output metadata, including removing all _FillValues.\n",
    "    all_vars = list(interped.data_vars.keys()) + list(interped.coords.keys())\n",
    "    encodings = {v: {'_FillValue': None} for v in all_vars}\n",
    "    encodings['time'].update({'dtype':'float64', 'calendar': 'gregorian'})\n",
    "    interped['zl'].attrs = {\n",
    "        'units': 'meter',\n",
    "        'cartesian_axis': 'Z',\n",
    "        'positive': 'down'\n",
    "    }\n",
    "\n",
    "    interped.to_netcdf(\n",
    "        output_file,\n",
    "        format='NETCDF3_64BIT',\n",
    "        engine='netcdf4',\n",
    "        encoding=encodings,\n",
    "        unlimited_dims='time'\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    # Use SODA data centered on 1992-12-30.\n",
    "    # Model start date is 1993-01-01.\n",
    "    # https://dsrs.atmos.umd.edu/DATA/soda3.12.2/REGRIDED/ocean/soda3.12.2_5dy_ocean_reg_1993_01_04.nc\n",
    "    soda_file = '/glade/scratch/jsimkins/SODA3.12.2/soda3.12.2_5dy_ocean_reg_1993_01_04.nc'\n",
    "    start_date = np.datetime64('1993-01-02T00:00:00')\n",
    "    # Used in filename below, don't change\n",
    "    start_str = np.datetime_as_string(start_date, unit='D')\n",
    "    \n",
    "    # Save the ICs here:\n",
    "    output_file = f'/glade/u/home/jsimkins/obc_ic/natlGrid/soda_ic_75z_{start_str}.nc'\n",
    "\n",
    "    # Model vertical grid:\n",
    "    vgrid_file = '/glade/u/home/jsimkins/obc_ic/natlGrid/vgrid_dz.nc'\n",
    "\n",
    "    # Model horizontal grid:\n",
    "    grid_file = '/glade/u/home/jsimkins/obc_ic/natlGrid/natl_ocean_hgrid.nc'\n",
    "\n",
    "    write_initial(soda_file, vgrid_file, grid_file, start_date, output_file)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
